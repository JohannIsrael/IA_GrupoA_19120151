{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html\n",
    "\n",
    "\n",
    "https://docs.opencv.org/2.4/doc/user_guide/ug_traincascade.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "x=y=w=h= 0 \n",
    "img = 0\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 5)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        m= int(h/2)\n",
    "        frame = cv.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "       # frame = cv.rectangle(frame, (x,y+m), (x+w, y+h), (255, 0 ,0), 2 )\n",
    "        frame2 = frame[y:y+h, x:x+w]\n",
    "        cv.imshow('rostros2', frame2)\n",
    "        cv.imwrite('./capturas/johann/'+str(i)+'.png', frame2)\n",
    "       # img = 180- frame[y:y+h,x:x+w]\n",
    "       # count = count + 1   \n",
    "\n",
    "        # !  para que las imágenes tengan el mismo tamaño se debe usar la función resize 100x100 px\n",
    "    #name = '/home/likcos/imgs/cara'+str(count)+'.jpg'\n",
    "    #cv.imwrite(name, frame)\n",
    "    cv.imshow('rostros', frame)\n",
    "    #cv.imshow('cara', img)\n",
    "    i = i+1 \n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para realizar la capturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "# Verificar si la carpeta de destino existe, si no, crearla\n",
    "output_dir = './capturas/johann/triste/'\n",
    "if not os.path.exists(output_dir):\n",
    "    print('No existe el directorio')\n",
    "    \n",
    "\n",
    "# Cargar el clasificador de Haar para la detección de rostros\n",
    "rostro = cv.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# Iniciar la captura de vídeo desde la cámara\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Contador para el nombre de los archivos de salida\n",
    "i = 333\n",
    "\n",
    "while True:\n",
    "    # Capturar un fotograma de la cámara\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convertir el fotograma a escala de grises\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detectar rostros en la imagen en escala de grises\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # Iterar sobre cada rostro detectado\n",
    "    for(x, y, w, h) in rostros:\n",
    "        # Dibujar un rectángulo alrededor del rostro detectado en el fotograma original\n",
    "        \n",
    "        # Dibujar un rectángulo alrededor del rostro detectado en el fotograma original\n",
    "        frame = cv.rectangle(frame, (x-20, y-20), (x+w+20, y+h+20), (0, 255, 0), 2)\n",
    "\n",
    "        # frame = cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Recortar el área del rostro detectado\n",
    "        frame2 = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Redimensionar el área del rostro a 100x100 píxeles\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_AREA)\n",
    "        \n",
    "        # Guardar el rostro redimensionado como una imagen PNG\n",
    "        cv.imwrite(output_dir+'johanntriste'+str(i)+'.png', frame2)\n",
    "        \n",
    "    # Mostrar el fotograma con los rostros detectados\n",
    "    cv.imshow('Rostros', frame)\n",
    "    \n",
    "    # Incrementar el contador de archivos de salida\n",
    "    i += 1\n",
    "    \n",
    "    # Esperar por la tecla ESC para salir del bucle\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Liberar los recursos de la cámara y cerrar las ventanas\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para generar el xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "dataSet = './capturas'\n",
    "emotions = ['triste', 'feliz', 'enojado', 'asombrado', 'neutro']\n",
    "faces  = os.listdir(dataSet)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0 \n",
    "\n",
    "\n",
    "# for face in faces:\n",
    "#     facePath = dataSet+'/'+face\n",
    "#     for faceName in os.listdir(facePath):\n",
    "#         labels.append(label)\n",
    "#         facesData.append(cv.imread(facePath+'/'+faceName,0))\n",
    "#     label = label + 1\n",
    "# print(np.count_nonzero(np.array(labels)==0)) \n",
    "\n",
    "# Iterar sobre cada emoción\n",
    "for emotion in emotions:\n",
    "    emotionPath = os.path.join(dataSet, emotion)\n",
    "    if not os.path.isdir(emotionPath):\n",
    "        continue  # Si el directorio de la emoción no existe, saltar\n",
    "\n",
    "    # Iterar sobre cada persona dentro de la emoción\n",
    "    for person in os.listdir(emotionPath):\n",
    "        personPath = os.path.join(emotionPath, person)\n",
    "        if not os.path.isdir(personPath):\n",
    "            continue  # Si no es un directorio, saltar\n",
    "\n",
    "        # Iterar sobre cada imagen de la persona\n",
    "        for faceName in os.listdir(personPath):\n",
    "            facePath = os.path.join(personPath, faceName)\n",
    "            if os.path.isfile(facePath):\n",
    "                labels.append(label)\n",
    "                facesData.append(cv.imread(facePath, 0))\n",
    "        label += 1\n",
    "\n",
    "print(f\"Total de imágenes de la emoción 'triste': {np.count_nonzero(np.array(labels) == 0)}\")\n",
    "print(f\"Total de imágenes de la emoción 'feliz': {np.count_nonzero(np.array(labels) == 1)}\")\n",
    "print(f\"Total de imágenes de la emoción 'enojado': {np.count_nonzero(np.array(labels) == 2)}\")\n",
    "print(f\"Total de imágenes de la emoción 'asombrado': {np.count_nonzero(np.array(labels) == 3)}\")\n",
    "print(f\"Total de imágenes de la emoción 'neutro': {np.count_nonzero(np.array(labels) == 4)}\")\n",
    "\n",
    "# faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "# faceRecognizer.train(facesData, np.array(labels))\n",
    "# faceRecognizer.write('laloEigenface.xml')\n",
    "\n",
    "# Entrenar el reconocedor de caras\n",
    "faceRecognizer = cv.face.EigenFaceRecognizer_create()\n",
    "faceRecognizer.train(facesData, np.array(labels))\n",
    "faceRecognizer.write('datasetEmotionEigenface.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataPath = './capturas' \n",
    "emotionList = os.listdir(dataPath)\n",
    "print('Lista de emociones: ', emotionList)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0\n",
    "\n",
    "# for nameDir in emotionList:\n",
    "# \tpersonPath = dataPath + '/' + nameDir\n",
    "# \t# print('Leyendo las imágenes')\n",
    "\n",
    "# \tfor fileName in os.listdir(personPath):\n",
    "# \t\t# print('Rostros: ', nameDir + '/' + fileName)\n",
    "# \t\tlabels.append(label)\n",
    "# \t\tfacesData.append(cv2.imread(personPath+'/'+fileName,0))\n",
    "# \t\t#image = cv2.imread(personPath+'/'+fileName,0)\n",
    "# \t\t#cv2.imshow('image',image)\n",
    "# \t\t#cv2.waitKey(10)\n",
    "# \tlabel = label + 1\n",
    "\n",
    "for emotionDir in emotionList:\n",
    "    emotionPath = os.path.join(dataPath, emotionDir)\n",
    "    print(f'Leyo las imágenes de la emoción: {emotionDir}')\n",
    "\n",
    "\n",
    "    for personDir in os.listdir(emotionPath):\n",
    "        personPath = os.path.join(emotionPath, personDir)\n",
    "\n",
    "        for fileName in os.listdir(personPath):\n",
    "            filePath = os.path.join(personPath, fileName)\n",
    "    \n",
    "            # Asegurarse de que el archivo es una imagen\n",
    "            if os.path.isfile(filePath):\n",
    "                image = cv2.imread(filePath, 0)\n",
    "                if image is not None:\n",
    "                    # Asegurarse de que todas las imágenes tienen el mismo tamaño\n",
    "                    if facesData and image.shape != facesData[0].shape:\n",
    "                        print(f'Error: las imágenes no tienen el mismo tamaño: {filePath}')\n",
    "                        continue\n",
    "                    labels.append(label)\n",
    "                    facesData.append(image)\n",
    "                    # cv2.imshow('image', image)\n",
    "                    # cv2.waitKey(10)\n",
    "                else:\n",
    "                    print(f'Error al leer la imagen: {filePath}')\n",
    "        label += 1\n",
    "\n",
    "\n",
    "print('labels= ',labels)\n",
    "print('Número de etiquetas 0: ',np.count_nonzero(np.array(labels)==0))\n",
    "print('Número de etiquetas 1: ',np.count_nonzero(np.array(labels)==1))\n",
    "\n",
    "# Métodos para entrenar el reconocedor\n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Entrenando el reconocedor de rostros\n",
    "print(\"Entrenando...\")\n",
    "face_recognizer.train(facesData, np.array(labels))\n",
    "\n",
    "# Almacenando el modelo obtenido\n",
    "#face_recognizer.write('modeloEigenFace.xml')\n",
    "#face_recognizer.write('modeloFisherFace.xml')\n",
    "face_recognizer.write('modeloLBPHFace.xml')\n",
    "print(\"Modelo almacenado...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para cargar el xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "cascade_path = 'haarcascade_frontalface_alt.xml'\n",
    "\n",
    "# Inicializar el reconocedor de caras\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Leer el modelo entrenado\n",
    "model_path = \"EmocionesmodeloLBPHFace.xml\"\n",
    "if os.path.exists(model_path):\n",
    "    print(\"El archivo del modelo existe\")\n",
    "    try:\n",
    "        faceRecognizer.read(model_path)\n",
    "        print(\"Modelo cargado con éxito\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el modelo: {e}\")\n",
    "else:\n",
    "    raise Exception(\"El archivo del modelo no existe\")\n",
    "\n",
    "# Definir etiquetas de emociones\n",
    "emotions = [\"enojo\", \"feliz\", \"asombrado\", \"triste\", \"neutro\"]\n",
    "\n",
    "# Inicializar la captura de video\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(\"No se pudo abrir el dispositivo de video\")\n",
    "\n",
    "# Cargar el Haar cascade para detección de rostros\n",
    "rostro = cv.CascadeClassifier(cascade_path)\n",
    "if rostro.empty():\n",
    "    raise Exception(\"Error al cargar el archivo Haar cascade\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error al capturar el cuadro\")\n",
    "        break\n",
    "    \n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    \n",
    "    for (x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        cv.putText(frame, f'{result}', (x, y-5), 1, 1.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        \n",
    "        if result[1] < 70:\n",
    "            cv.putText(frame, f'{emotions[result[0]]}', (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv.putText(frame, 'No identificado', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == 27:  # Presiona 'ESC' para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si existe el archivo  {'haarcascade_frontalface_alt.xml'}\n",
      "si existe el archivo  {'EmocionesmodeloLBPHFace.xml'}\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\persistence.cpp:1601: error: (-215:Assertion failed) ofs == fs_data_blksz[blockIdx] in function 'cv::FileStorage::Impl::normalizeNodeOfs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m faceRecognizer \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mface\u001b[38;5;241m.\u001b[39mLBPHFaceRecognizer_create()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Read the trained model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mfaceRecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Define emotion labels\u001b[39;00m\n\u001b[0;32m     25\u001b[0m faces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menojo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeliz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorpresa\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\persistence.cpp:1601: error: (-215:Assertion failed) ofs == fs_data_blksz[blockIdx] in function 'cv::FileStorage::Impl::normalizeNodeOfs'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "# Verifica que exista el archivo\n",
    "cascade_path = 'haarcascade_frontalface_alt.xml'\n",
    "if not os.path.isfile(cascade_path):\n",
    "    raise FileNotFoundError(f\"El archivo '{cascade_path}' no existe\")\n",
    "else:\n",
    "    print('si existe el archivo ', {cascade_path})\n",
    "\n",
    "# Verifica que exista el archivo\n",
    "model_path = \"EmocionesLBPHZwei.xml\"\n",
    "if not os.path.isfile(model_path):\n",
    "    raise FileNotFoundError(f\"El archivo '{model_path}' no exite\")\n",
    "else:\n",
    "    print('si existe el archivo ', {model_path})\n",
    "\n",
    "# Initialize face recognizer\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Read the trained model\n",
    "faceRecognizer.read(model_path)\n",
    "\n",
    "# Define emotion labels\n",
    "faces = [\"enojo\", \"feliz\", \"sorpresa\"]\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise Exception(\"Could not open video device\")\n",
    "\n",
    "# Load the Haar cascade for face detection\n",
    "rostro = cv.CascadeClassifier(cascade_path)\n",
    "if rostro.empty():\n",
    "    raise Exception(\"Failed to load Haar cascade file\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    \n",
    "    for (x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2, (100, 100), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        cv.putText(frame, f'{result}', (x, y-5), 1, 1.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        \n",
    "        # Display the prediction result\n",
    "        # if result[1] < 100:\n",
    "        #     cv.putText(frame, f'{faces[result[0]]}', (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        #     cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        # else:\n",
    "        #     cv.putText(frame, 'Desconocido', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "        #     cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        if result[1] < 70:\n",
    "            cv.putText(frame, f'{emotions[result[0]]}', (x, y-25), 2, 1.1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv.putText(frame, 'No identificado', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == 27:  # Press 'ESC' to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
